[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Recap",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nOffline Reinforcement Learning\n\n\n\n\n\n\n\nRL\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2023\n\n\nVaibhav Balloli\n\n\n\n\n\n\n\n\nLessons from writing Research Code\n\n\n\n\n\n\n\ncode\n\n\nsetup\n\n\nresearch\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2022\n\n\nVaibhav Balloli\n\n\n\n\n\n\n\n\nDevelopment Setup\n\n\n\n\n\n\n\ncode\n\n\nsetup\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2022\n\n\nVaibhav Balloli\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/dev-setup/index.html",
    "href": "posts/dev-setup/index.html",
    "title": "Development Setup",
    "section": "",
    "text": "My programming language of choice has mostly been Python lately, with dev both on Linux and Windows (and WSL) - both when I’m working on personal and professional projects. While some of it keeps me awake for quite a long time based on the criticality of the project, it becomes essential that the tools and commands I use are handy, ubiquitous and uniform across my machines. This post showcases some of these and will be updated continuously."
  },
  {
    "objectID": "posts/dev-setup/index.html#libraries-and-frameworks",
    "href": "posts/dev-setup/index.html#libraries-and-frameworks",
    "title": "Development Setup",
    "section": "Libraries and Frameworks",
    "text": "Libraries and Frameworks\n\nNumba - makes things go vroom.\nFastcore - reduces regular boilerplate by quite a lot.\nStreamlit - host dashboard to present to multiple people asynchronously and remotely.\nRay - large scale distributed code.\nDask - host cluster on remote machines and send compute to these clusters. fast pandas alternative\nSphinx - build and host documentation\nFastAPI - web framework of choice\nPostgreSQL - database of choice\nsqlalchemy - ORM of choice\nHydra - config management\nWandb/mlflow - experiment tracker personal/professional"
  },
  {
    "objectID": "posts/dev-setup/index.html#ray-and-ray-ecosystem",
    "href": "posts/dev-setup/index.html#ray-and-ray-ecosystem",
    "title": "Development Setup",
    "section": "Ray and Ray ecosystem",
    "text": "Ray and Ray ecosystem\nRay’s approach towards multiprocessing is something I find very intuitive and natural as opposed to doing everything by hand. I prefer using everything Ray: including the hyperparameter search library(Ray’s tune), RLLib for some standard RL stuff, etc. I highly suggest investing time in understanding Ray and surrounding concepts."
  },
  {
    "objectID": "posts/dev-setup/index.html#sphinx-and-boilerplate",
    "href": "posts/dev-setup/index.html#sphinx-and-boilerplate",
    "title": "Development Setup",
    "section": "Sphinx and Boilerplate",
    "text": "Sphinx and Boilerplate\nThe template below can be used very easily to write, build and host documentation and suggested for medium to large projects.\n\nrequirements.txtconf.py\n\n\nbreathe==4.30.0\nfuro\ngit+https://github.com/sphinx-contrib/video\nipywidgets\njupyter-sphinx\nmyst-nb\nmyst-parser\nnbsphinx\npandoc\nsphinx\nsphinx-autobuild\nsphinx-book-theme\nsphinx-copybutton\nsphinx-design\nsphinx-proof\nsphinx-tabs\nsphinx-togglebutton\nsphinx_markdown_builder\nsphinxemoji\nsphinxcontrib-youtube\npandoc\n\n\nimport os\nimport sys\n\nsys.path.append('../')\n\n\n# -- Project information -----------------------------------------------------\n\nproject = '<Project Name>'\ncopyright = '<ADD COPYRIGHT>'\nauthor = '<ADD AUTHORS>'\n\n# The full version, including alpha/beta/rc tags\nrelease = '0.1'\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.doctest\",\n    \"sphinx.ext.autosummary\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.coverage\",\n    \"sphinx.ext.mathjax\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.autosectionlabel\",\n    \"sphinxemoji.sphinxemoji\",\n    \"breathe\",\n    \"sphinx_markdown_builder\",\n    \"sphinx_copybutton\",\n    \"jupyter_sphinx\",\n    # \"myst_nb\",\n    \"myst_parser\",\n    \"sphinx_proof\",\n    \"sphinx_design\",\n    \"sphinxcontrib.video\",\n    \"sphinx_togglebutton\",\n    \"sphinx_tabs.tabs\",\n    \"nbsphinx\",\n    \"sphinxcontrib.youtube\",\n]\nautodoc_typehints = \"description\"\nautodoc_class_signature = \"separated\"\nautosummary_generate = True\nautodoc_default_options = {\n    \"members\": True,\n    \"inherited-members\": True,\n    \"show-inheritance\": False,\n}\nautodoc_inherit_docstrings = True\nmyst_enable_extensions = [\"colon_fence\"]\n\nnb_execution_mode = \"off\"\nnbsphinx_allow_errors = True\nnbsphinx_execute = \"never\"\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = [\"_build\", \"Thumbs.db\", \".DS_Store\"]\n\nhtml_theme_options = {\n    \"repository_url\": \"https://github.com/PROJECT_ORG/PROJECT_NAME\",\n    \"use_repository_button\": True,\n    \"use_download_button\": True,\n}\n\nhtml_title = \"Docs Title\"\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n# html_theme = \"furo\"\nhtml_theme = \"sphinx_book_theme\"\n\n# removes the .txt suffix\nhtml_sourcelink_suffix = \"\"\n\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"static\"]\n\nautodoc_mock_imports = [] #libraries you don't want to install when building the docs"
  },
  {
    "objectID": "posts/offline-rl/index.html",
    "href": "posts/offline-rl/index.html",
    "title": "Offline Reinforcement Learning",
    "section": "",
    "text": "Reinforcement Learning(RL), as simply stated in Sutton and Barto Sutton and Barto (2018) , is learning what to do i.e map situations to actions to maximize the cumulative reward for a series of steps. Naturally, trial and error is at the core of Reinforcement Learning i.e. RL learns in a hands-on approach exploring and exploiting its task, which is referred to as online learning, where online refers to agent manipulating the surroundings around it(commonly referred to as an Environment) with the available controls it has(referred to as actions). While such approaches have been popular and successful in many tasks, they often rely on continually improving the ability to search better and learn on the go, which does not translate well to tasks where the ability to explore the environment comes with a cost, which harms the ability of most state-of-the-art algorithms to learn. Hence, Offline Reinforcement Learning is a paradigm within RL that is tasked to learn optimal behaviour from a static dataset i.e. the available data is fixed and cannot be controlled, as it is often generated from an external agent. The figure below illustrates the key difference between traditional RL and offline RL.\n\n\n\nIllustration of Traditional RL interactions vs Offline RL(credit: Offline RL NeurIPS )\n\n\nIn this post, I cover some popular algorithms and code excerpts that help understand some of the implementation details regarding these algorithms to provide the intuition of how they work. For more documentation on how to run these algorithms, you can check out my repository that implements these algorithms in detail at Offlax:\n\n\nConservative Q-Learning(CQL) builds on top of existing algorithms like QR-DQN(for discrete action spaces) and SAC(for continuous action spaces). As the paper suggests, CQL only requires 20 lines of additional code over the existing RL algorithms like QR-DQN and SAC.\n\n\n\nBehavior cloning is a widely used techniques to for agents to learn from an expert i.e. trying to understand based on an expert agent’s trajectory. This paper suggests using Behavior Cloning with some adjustments over an existing RL algorithm like TD3 to learn in from a static dataset of trajectories."
  },
  {
    "objectID": "posts/research-code/index.html",
    "href": "posts/research-code/index.html",
    "title": "Lessons from writing Research Code",
    "section": "",
    "text": "Having written a good amount of research code for a while now, I was wondering what “good research code” can be construed as. This topic has been discussed heavily with a lot of good blog posts and materials on the internet (some I’ve found: Hongyuan Mei’s blog, Good Research Code Handbook, etc.). Personally, I have a checklist of things that potrays my version of the basic requirements of good research code, in the context of ease of use for other researchers/practioners:\nSpecial note: A good documentation in my observation(see point 2. above) has immensely helped me in navigating relatively new fields of research, particularly in Machine Learning."
  },
  {
    "objectID": "posts/research-code/index.html#but-why-invest-additional-time-in-this",
    "href": "posts/research-code/index.html#but-why-invest-additional-time-in-this",
    "title": "Lessons from writing Research Code",
    "section": "But why invest additional time in this ?",
    "text": "But why invest additional time in this ?\nThe recent trend suggests that most research code goes through multiple phases:\n\nQuick, dirty implementation of the idea in mind\nWrite scripts to get results\nMake code public\n\nIdeally, it should be something like this:\n\nQuick, dirty implementation of the idea in mind.\nTidy code, structured implementation of both the boiler plate, previous work and the core contribution.\nWrite reproducible scripts and automate most metric collection, results charting and documentation to reduce manual work.\nOnce code goes public, spending some time in maintaining/addressing user issues.\n\nYou’ll notice it’s the second point that differentiates between good and terrible practices - tidying up code at the right time. Given the results of the quick prototype that backed your idea, it’s clear that you’ll be investing a good portion of your time diving deep into all the nuances of this prototype. This means there should be more research and less manual work. What manual work refers to here is often times bad code can result in a lot of manual work of coarsing through csvs, logs, metadata, and other things that shifts the focus from research to running scripts manually.\nThis means the tools you use(IDE, software, hardware) etc. is something you should be familiar with, mostly from previous experience on other projects. This ensures that: 1. Not a lot of time is spent on setup (at the start of the project) and publishing (at the end of the project) 2. Working within a comfortable zone of tools ensures productivity and consistency.\nMy dev setup is a culmination of mostly research and some non-research tools that is mostly oriented towards working on Windows based local machines with WSL and Linux machines with GPUs."
  }
]